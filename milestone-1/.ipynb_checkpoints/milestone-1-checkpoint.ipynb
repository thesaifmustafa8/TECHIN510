{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea1b194",
   "metadata": {},
   "source": [
    "# TECHIN 510\n",
    "## Milestone 1\n",
    "\n",
    "**Name**: Saif Mustafa\n",
    "\n",
    "**Email**: saifm@uw.edu\n",
    "\n",
    "**Student Number**: 1428039\n",
    "\n",
    "---\n",
    "\n",
    "As part of the first milestone for your projects, you will practice what you have learned so far by developing the visual recognition capabilities of the robot you choose to develop. As a first step read the project topics listed below and decide which topic you would like to work on. You will choose and implement two visual recognition functionalities from the specs listed in the project topic you choose.\n",
    "\n",
    "Your implementation will be in Python. You can use everything covered in class as well as any new functionality you discover yourself.\n",
    "\n",
    "You will complete this assignment by submitting a demo video and any materials (code, data, physical prompts) that would allow us to recreate your demo, on Canvas by Oct 29, 2021 (Friday). The video should clearly illustrate two functionalities. Make sure you demonstrate the functionality in varied scenarios (e.g., for face detection make sure you have at least two different people's faces in different poses relative to the camera). At this point, your video does not need to include narrative about the project. It can be as simple as a screenshot video showing the captured images from a camera with annotations that reflect the implemented functionalities (e.g. square around faces for face detection).\n",
    "\n",
    "---\n",
    "\n",
    "## Topic: Nike Exercise and Wellness Robot\n",
    "\n",
    "**Problem:** Many people who know the importance and potential benefits of exercising and meditation have a hard time motivating themselves to actually do them.\n",
    "\n",
    "**Proposed solution:** Social robots have been demonstrated to have the impact of a social accountability partner in committing to difficult behavioral changes. This project will explore this potential of social robots for exercise, yoga, and/or meditation motivation and guidance.\n",
    "\n",
    "**Prototype specifications:** The robot will have one user. The robot should interact with the user to introduce itself, meet its user, set user goals, and motivate the user to reach those goals. It should also guide the user through a sample exercise.\n",
    "\n",
    "**Image processing capabilities for this robot (Milestone 1):**\n",
    "- determine when a person is in front of the robot, \n",
    "- recognize whether the person is the owner of the robot, \n",
    "- determine the mood of the person, \n",
    "- determine when a person has completed an exercise, \n",
    "- determine when a functionality activation card (e.g. to start a specific exercise) is visually shown to the robot.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c63604",
   "metadata": {},
   "source": [
    "##  Installs / Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3666673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (0.8.8.1)\n",
      "Requirement already satisfied: numpy in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (1.19.5)\n",
      "Requirement already satisfied: absl-py in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (0.15.0)\n",
      "Requirement already satisfied: six in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (1.15.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: matplotlib in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (3.3.4)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (3.19.1)\n",
      "Requirement already satisfied: wheel in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (0.36.2)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from mediapipe) (4.5.4.58)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: opencv-python in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (4.5.4.58)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from opencv-python) (1.19.5)\n",
      "Requirement already satisfied: deepface in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (0.0.68)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from deepface) (8.2.0)\n",
      "Requirement already satisfied: tqdm>=4.30.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from deepface) (4.59.0)\n",
      "Requirement already satisfied: tensorflow>=1.9.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from deepface) (2.6.0)\n",
      "Requirement already satisfied: keras>=2.2.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from deepface) (2.6.0)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from deepface) (1.2.4)\n",
      "Requirement already satisfied: retina-face>=0.0.1 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from deepface) (0.0.5)\n",
      "Requirement already satisfied: gdown>=3.10.1 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from deepface) (4.2.0)\n",
      "Requirement already satisfied: opencv-python>=3.4.4 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from deepface) (4.5.4.58)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from deepface) (1.19.5)\n",
      "Requirement already satisfied: Flask>=1.1.2 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from deepface) (1.1.2)\n",
      "Requirement already satisfied: mtcnn>=0.1.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from deepface) (0.1.1)\n",
      "Requirement already satisfied: click>=5.1 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from Flask>=1.1.2->deepface) (7.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from Flask>=1.1.2->deepface) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from Flask>=1.1.2->deepface) (1.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from Flask>=1.1.2->deepface) (2.11.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from gdown>=3.10.1->deepface) (4.9.3)\n",
      "Requirement already satisfied: filelock in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from gdown>=3.10.1->deepface) (3.0.12)\n",
      "Requirement already satisfied: six in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from gdown>=3.10.1->deepface) (1.15.0)\n",
      "Requirement already satisfied: requests[socks] in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from gdown>=3.10.1->deepface) (2.25.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from Jinja2>=2.10.1->Flask>=1.1.2->deepface) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.23.4->deepface) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.23.4->deepface) (2021.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
      "Requirement already satisfied: clang~=5.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (5.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (2.7.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (1.41.1)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (1.12.1)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (3.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (0.15.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (3.19.1)\n",
      "Requirement already satisfied: gast==0.4.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (3.7.4.3)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (2.7.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=1.9.0->deepface) (0.36.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (2.3.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.3.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->gdown>=3.10.1->deepface) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->gdown>=3.10.1->deepface) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.2.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/thesaifmustafa/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "# installing opencv and mediapipe https://google.github.io/mediapipe/\n",
    "!pip install mediapipe\n",
    "!pip install opencv-python\n",
    "!pip install deepface\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils # drawing model\n",
    "mp_pose = mp.solutions.pose # pose estimation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a5781b",
   "metadata": {},
   "source": [
    "## Video Code + Basic detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9e171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width = 1280.0\n",
      "height = 720.0\n"
     ]
    }
   ],
   "source": [
    "# find out my mac's webcam dimensions\n",
    "\n",
    "vcap = cv2.VideoCapture(0) # 0=camera\n",
    " \n",
    "if vcap.isOpened(): \n",
    "    # get vcap property \n",
    "    width  = vcap.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
    "    height = vcap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
    "\n",
    "    # it gives me 0.0 :/\n",
    "    fps = vcap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    print(\"width =\",width)\n",
    "    print(\"height =\",height)\n",
    "    \n",
    "    # 1280 x 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1cba662",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'landmark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0c7dfcafd849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# basic detection using the draw_landmarks utility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'landmark'"
     ]
    }
   ],
   "source": [
    "# https://docs.opencv.org/master/dd/d43/tutorial_py_video_display.html\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "    \n",
    "# setting detection and tracking confidence    \n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while True:\n",
    "        \n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # if frame is read correctly ret is True\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        \n",
    "        # Our operations on the frame come here\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        \n",
    "        # basic detection using the draw_landmarks utility\n",
    "        mp_drawing.draw_landmarks(image, # image\n",
    "                                  results.pose_landmarks, # coordinates\n",
    "                                  mp_pose.POSE_CONNECTIONS, # pose connections\n",
    "                                  mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2), # dots\n",
    "                                  mp_drawing.DrawingSpec(thickness=2, circle_radius=2)) # connections\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('NIKE WELLNESS DETECTOR', image)\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_drawing.draw_landmarks??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f173e4b",
   "metadata": {},
   "source": [
    "## Identifying joints\n",
    "\n",
    "Mediapipe all usable body landmarks.\n",
    "\n",
    "- 33 landmarks in total\n",
    "- index starting at 0\n",
    "- represent joints within the pose\n",
    "\n",
    "\n",
    "![Mediapipe body landmarks](https://google.github.io/mediapipe/images/mobile/pose_tracking_full_body_landmarks.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8721b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappings\n",
    "i = 0\n",
    "for dot in mp_pose.PoseLandmark:\n",
    "    print(i, \"=\", dot)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ae383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the specific coordinates to a given landmark:\n",
    "landmarks[mp_pose.PoseLandmark.NOSE.value] # nose\n",
    "# or\n",
    "landmarks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae1552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure curls -- need 11, 13, 15\n",
    "landmarks[11] # left shoulder\n",
    "landmarks[13] # left elbow\n",
    "landmarks[15] # left wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0badcbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouth example\n",
    "mouth = [landmarks[mp_pose.PoseLandmark.MOUTH_LEFT.value].x,\n",
    "         landmarks[mp_pose.PoseLandmark.MOUTH_RIGHT.value].y,\n",
    "         landmarks[mp_pose.PoseLandmark.MOUTH_RIGHT.value].z]\n",
    "\n",
    "mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# angle needed between shoulder, elbow, and wrist to determine curl\n",
    "# just doing x and y for now\n",
    "\n",
    "shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "\n",
    "elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "         landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "\n",
    "wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "         landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "shoulder, elbow, wrist\n",
    "\n",
    "get_angle(shoulder, elbow, wrist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4817cc1",
   "metadata": {},
   "source": [
    "## Angle calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247dc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get angle between any 3 given points\n",
    "def get_angle(p1, p2, p3):\n",
    "    \n",
    "    p1 = np.array(p1)\n",
    "    p2 = np.array(p2)\n",
    "    p3 = np.array(p3)\n",
    "    \n",
    "    radians = np.arctan2(p3[1]-p2[1], p3[0]-p2[0]) - np.arctan2(p1[1]-p2[1], p1[0]-p2[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5d994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9d6dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80607f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81c3e685",
   "metadata": {},
   "source": [
    "## Building a counter / tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436fc950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saif\n"
     ]
    }
   ],
   "source": [
    "# https://docs.opencv.org/master/dd/d43/tutorial_py_video_display.html\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"Saif\")\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "    \n",
    "curl_count=0\n",
    "curl_flag_left=\"down\"\n",
    "curl_flag_right=\"False\"\n",
    "    \n",
    "# setting detection and tracking confidence    \n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while True:\n",
    "        \n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # if frame is read correctly ret is True\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        \n",
    "        # Our operations on the frame come here\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract all joints\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # shoulder coordinates\n",
    "            shoulder_left = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            #print(\"Shoulder left =\",shoulder_left)\n",
    "            \n",
    "            shoulder_right = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            #print(\"Shoulder right =\",shoulder_right)\n",
    "            \n",
    "            # elbow coordinates\n",
    "            elbow_left = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            \n",
    "            elbow_right = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "\n",
    "            # wrist coordinates\n",
    "            wrist_left = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            wrist_right = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                           landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # calculate angle\n",
    "            # logic:\n",
    "            # - if angle is > 90, then it's a curl down\n",
    "            # - if angle < 90, the it's a curl up\n",
    "            # - some kind of counter that starts and countfs every 2 as 1 successful curl\n",
    "            # - visualize on screen\n",
    "            curl_angle_left = get_angle(shoulder_left, elbow_left, wrist_left)\n",
    "            #print(\"Curl angle left =\", curl_angle_left)\n",
    "            curl_angle_right = get_angle(shoulder_right, elbow_right, wrist_right)\n",
    "            #print(\"Curl angle right =\", curl_angle_right)\n",
    "            \n",
    "            # show angle at elbow\n",
    "            cv2.putText(image, \n",
    "                        str(round(curl_angle_right)), \n",
    "                        tuple(np.multiply(elbow_right, [1280,720]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)\n",
    "\n",
    "            cv2.putText(image, \n",
    "                        str(round(curl_angle_left)), \n",
    "                        tuple(np.multiply(elbow_left, [1280,720]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,255,0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            # print(\"Count = \",curl_count)\n",
    "            \n",
    "            if curl_angle_left > 160:\n",
    "                curl_flag_left = False # curl down\n",
    "            if curl_angle_left < 50 and not curl_flag_left:\n",
    "                curl_flag_left = True # curl up\n",
    "                curl_count+=1\n",
    "                print(\"Count inside = \", curl_count)\n",
    "                \n",
    "            if curl_angle_right > 160:\n",
    "                curl_flag_right=False # curl down\n",
    "            if curl_angle_right < 50 and not curl_flag_right:\n",
    "                curl_flag_right=True # curl up\n",
    "                curl_count+=1\n",
    "                print(\"Count inside = \", curl_count)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # display count\n",
    "        #cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "        #cv2.rectangle(image,(0,620),(1280,720),(0,0,0),-1)\n",
    "        cv2.putText(image, \"NIKE FITNESS TRACKER\", (500,600),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.rectangle(image, (600,610), (700,710), (69,255,213), -1) # rgba(213,255,69,255)\n",
    "        cv2.putText(image, \"REPS\", (635,635),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, .4, (120,116,124), 1, cv2.LINE_AA) # rgb(124,116,120)\n",
    "        cv2.putText(image, str(curl_count), (640,675),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 1, (0,0,0), 2, cv2.LINE_AA) # rgb(124,116,120)\n",
    "        \n",
    "        \n",
    "        # basic detection using rhe draw_landmarks utility\n",
    "        mp_drawing.draw_landmarks(image, # image\n",
    "                                  results.pose_landmarks, # coordinates\n",
    "                                  mp_pose.POSE_CONNECTIONS, # pose connections\n",
    "                                  mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2), # dots\n",
    "                                  mp_drawing.DrawingSpec(thickness=2, circle_radius=2)) # connections\n",
    "        \n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('NIKE WELLNESS DETECTOR', image)\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b27d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56837a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14892872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f7f790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26055a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a66ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c971c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05282a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
